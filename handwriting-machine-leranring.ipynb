{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ahmedelmaamounamin/handwritten-digit-recognition-with-gui?scriptVersionId=214302649\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"eedaa33d","metadata":{"papermill":{"duration":0.003005,"end_time":"2024-12-22T14:04:36.945513","exception":false,"start_time":"2024-12-22T14:04:36.942508","status":"completed"},"tags":[]},"source":["# Handwritten Digit Recognition with GUI\n","\n","This project implements a handwritten digit recognition system using the MNIST dataset and provides a graphical user interface (GUI) for users to draw digits and have them recognized by a trained neural network model. The project is implemented in Python and utilizes various libraries, including PyTorch and Tkinter.\n","\n","## Project Components\n","1. **Neural Network Model**\n","\n","   A Convolutional Neural Network (CNN) model is defined using PyTorch. This model is designed for handwritten digit recognition.\n","\n","   The model consists of convolutional layers, fully connected layers, and dropout layers to prevent overfitting.\n","\n","2. **Data Loading and Preprocessing**\n","\n","   The MNIST dataset is loaded and preprocessed. It includes normalization and data augmentation for training.\n","\n","3. **Training**\n","\n","   The model is trained on the MNIST dataset. The training loop runs for a specified number of epochs, and the model is optimized using the Adam optimizer and Cross-Entropy loss.\n","\n","4. **Saving and Loading Model**\n","\n","   The trained model is saved to a file for later use.\n","\n","5. **GUI for Digit Recognition**\n","\n","   A GUI is created using the Tkinter library, allowing users to draw digits on a canvas.\n","\n","6. **Digit Prediction**\n","\n","   The drawn digit is processed, resized to the appropriate dimensions, and converted into a PyTorch tensor.\n","\n","   The trained model is used to predict the digit, and the result is displayed to the user.\n","\n","7. **Clear and Predict Buttons**\n","\n","   The GUI features buttons to clear the canvas and initiate the digit prediction.\n","\n","## How to Use\n","1. Execute the Python code and remove the comments in the code section.\n","2. The GUI will appear, allowing you to draw a digit on the canvas.\n","3. Click the \"Clear\" button to erase the drawing and start over.\n","4. Click the \"Predict\" button to have the model recognize and display the predicted digit.\n","\n","This project combines machine learning, computer vision, and GUI development to create an interactive handwritten digit recognition tool. Users can draw digits, and the model predicts the written number, making it a great demonstration of AI in action.\n"]},{"cell_type":"code","execution_count":1,"id":"70d9baf8","metadata":{"execution":{"iopub.execute_input":"2024-12-22T14:04:36.952255Z","iopub.status.busy":"2024-12-22T14:04:36.951842Z","iopub.status.idle":"2024-12-22T14:04:40.829318Z","shell.execute_reply":"2024-12-22T14:04:40.828131Z"},"papermill":{"duration":3.883909,"end_time":"2024-12-22T14:04:40.832159","exception":false,"start_time":"2024-12-22T14:04:36.94825","status":"completed"},"tags":[]},"outputs":[],"source":["# Import libraries \n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, transforms\n","import numpy as np\n","from PIL import Image, ImageDraw\n","import tkinter as tk"]},{"cell_type":"code","execution_count":2,"id":"3ce5772e","metadata":{"execution":{"iopub.execute_input":"2024-12-22T14:04:40.838851Z","iopub.status.busy":"2024-12-22T14:04:40.838291Z","iopub.status.idle":"2024-12-22T14:04:40.846283Z","shell.execute_reply":"2024-12-22T14:04:40.845183Z"},"papermill":{"duration":0.013737,"end_time":"2024-12-22T14:04:40.848399","exception":false,"start_time":"2024-12-22T14:04:40.834662","status":"completed"},"tags":[]},"outputs":[],"source":["# Define a CNN model in PyTorch\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n","        self.fc1 = nn.Linear(12*12*64, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.conv1(x))\n","        x = torch.relu(self.conv2(x))\n","        x = torch.max_pool2d(x, 2)\n","        x = self.dropout(x)\n","        x = x.view(-1, 12*12*64)\n","        x = torch.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return torch.log_softmax(x, dim=1)"]},{"cell_type":"code","execution_count":3,"id":"df757e09","metadata":{"execution":{"iopub.execute_input":"2024-12-22T14:04:40.854546Z","iopub.status.busy":"2024-12-22T14:04:40.854212Z","iopub.status.idle":"2024-12-22T14:04:47.6946Z","shell.execute_reply":"2024-12-22T14:04:47.69327Z"},"papermill":{"duration":6.846303,"end_time":"2024-12-22T14:04:47.697115","exception":false,"start_time":"2024-12-22T14:04:40.850812","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 12931804.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 340643.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 3210058.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 3271038.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Load MNIST data and apply transformations\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True, transform=transform),\n","    batch_size=128, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transform),\n","    batch_size=128, shuffle=False)"]},{"cell_type":"code","execution_count":4,"id":"be77df1f","metadata":{"execution":{"iopub.execute_input":"2024-12-22T14:04:47.707433Z","iopub.status.busy":"2024-12-22T14:04:47.706738Z","iopub.status.idle":"2024-12-22T14:17:14.303459Z","shell.execute_reply":"2024-12-22T14:17:14.302335Z"},"papermill":{"duration":746.604388,"end_time":"2024-12-22T14:17:14.305795","exception":false,"start_time":"2024-12-22T14:04:47.701407","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.297302\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.368735\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.153528\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.152530\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.082008\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.183334\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.156608\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.157424\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.105509\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.055097\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.058385\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.090344\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.059637\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.062918\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.087323\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.068242\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.082759\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.230477\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.177783\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.032666\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.024545\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.111476\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.034100\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.056043\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.031189\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.076929\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.020969\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.064533\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.058687\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.041179\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.057122\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.086136\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.100914\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.026054\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.068008\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.124935\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.010367\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.041902\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.017236\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.052026\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.033678\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.030050\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.081298\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.018337\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.061455\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.023906\n","Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.041545\n","Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.017410\n","Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.052224\n","Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.031168\n"]},{"data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=10, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Create the model, optimizer, and loss function\n","model = Net()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Training loop\n","def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 100 == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n","                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","# Train the model\n","for epoch in range(1, 11):\n","    train(epoch)\n","\n","# Save the model\n","torch.save(model.state_dict(), \"mnist_model.pth\")\n","\n","# Load the model\n","model = Net()\n","model.load_state_dict(torch.load(\"mnist_model.pth\"))\n","model.eval()"]},{"cell_type":"markdown","id":"da30e375","metadata":{"papermill":{"duration":0.00622,"end_time":"2024-12-22T14:17:14.318796","exception":false,"start_time":"2024-12-22T14:17:14.312576","status":"completed"},"tags":[]},"source":["# Digit Recognition: Draw and Predict\n","\n","# To use the Handwritten Digit Recognition GUI, follow these steps:\n","\n","1. Remove the comments (''' triple quotes ''') in the code below.\n","2. Run the code cell.\n","\n","After running the code, the GUI will appear, allowing you to draw a digit on the canvas. You can use the following functions:\n","\n","- **Clear:** Click the \"Clear\" button to erase the drawing and start over.\n","- **Predict:** Click the \"Predict\" button to have the model recognize and display the predicted digit."]},{"cell_type":"code","execution_count":5,"id":"6d586158","metadata":{"execution":{"iopub.execute_input":"2024-12-22T14:17:14.333398Z","iopub.status.busy":"2024-12-22T14:17:14.333021Z","iopub.status.idle":"2024-12-22T14:17:14.340743Z","shell.execute_reply":"2024-12-22T14:17:14.339695Z"},"papermill":{"duration":0.01755,"end_time":"2024-12-22T14:17:14.342804","exception":false,"start_time":"2024-12-22T14:17:14.325254","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\ndef predict_digit(img):\\n    # Resize and invert colors\\n    img = img.resize((28, 28))\\n    img = img.convert(\\'L\\')\\n    img = np.array(img)\\n    img = img.reshape(1, 1, 28, 28)\\n    img = img / 255.0\\n\\n    # Convert to PyTorch tensor\\n    img = torch.FloatTensor(img)\\n\\n    # Predicting the digit\\n    with torch.no_grad():\\n        output = model(img)\\n    _, predicted = torch.max(output, 1)\\n    return predicted.item()\\n\\ndef draw(event):\\n    x = event.x\\n    y = event.y\\n    draw_canvas.line([(x, y), (x+1, y+1)], fill=\\'black\\', width=8)\\n\\ndef clear():\\n    global image, draw_canvas\\n    image = Image.new(\"RGB\", (200, 200), (255, 255, 255))\\n    draw_canvas = ImageDraw.Draw(image)\\n    canvas.delete(\"all\")\\n\\ndef predict():\\n    digit = predict_digit(image)\\n    label.configure(text=str(digit))\\n\\n\\n\\nroot = tk.Tk()\\n\\ncanvas = tk.Canvas(root, width=200, height=200, bg=\\'white\\')\\ncanvas.grid(row=0, column=0, pady=2, sticky=tk.W)\\n\\nbutton_clear = tk.Button(root, text=\"Clear\", command=clear)\\nbutton_clear.grid(row=1, column=0, pady=2)\\n\\nbutton_predict = tk.Button(root, text=\"Predict\", command=predict)\\nbutton_predict.grid(row=1, column=1, pady=2)\\n\\nlabel = tk.Label(root, text=\"\", font=(\"Helvetica\", 48))\\nlabel.grid(row=0, column=1, pady=2, padx=2)\\n\\ncanvas.bind(\"<B1-Motion>\", draw)\\n\\nimage = Image.new(\"RGB\", (200, 200), (255, 255, 255))\\ndraw_canvas = ImageDraw.Draw(image)\\n\\nroot.mainloop()\\n\\n'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","def predict_digit(img):\n","    # Resize and invert colors\n","    img = img.resize((28, 28))\n","    img = img.convert('L')\n","    img = np.array(img)\n","    img = img.reshape(1, 1, 28, 28)\n","    img = img / 255.0\n","\n","    # Convert to PyTorch tensor\n","    img = torch.FloatTensor(img)\n","\n","    # Predicting the digit\n","    with torch.no_grad():\n","        output = model(img)\n","    _, predicted = torch.max(output, 1)\n","    return predicted.item()\n","\n","def draw(event):\n","    x = event.x\n","    y = event.y\n","    draw_canvas.line([(x, y), (x+1, y+1)], fill='black', width=8)\n","\n","def clear():\n","    global image, draw_canvas\n","    image = Image.new(\"RGB\", (200, 200), (255, 255, 255))\n","    draw_canvas = ImageDraw.Draw(image)\n","    canvas.delete(\"all\")\n","\n","def predict():\n","    digit = predict_digit(image)\n","    label.configure(text=str(digit))\n","\n","\n","\n","root = tk.Tk()\n","\n","canvas = tk.Canvas(root, width=200, height=200, bg='white')\n","canvas.grid(row=0, column=0, pady=2, sticky=tk.W)\n","\n","button_clear = tk.Button(root, text=\"Clear\", command=clear)\n","button_clear.grid(row=1, column=0, pady=2)\n","\n","button_predict = tk.Button(root, text=\"Predict\", command=predict)\n","button_predict.grid(row=1, column=1, pady=2)\n","\n","label = tk.Label(root, text=\"\", font=(\"Helvetica\", 48))\n","label.grid(row=0, column=1, pady=2, padx=2)\n","\n","canvas.bind(\"<B1-Motion>\", draw)\n","\n","image = Image.new(\"RGB\", (200, 200), (255, 255, 255))\n","draw_canvas = ImageDraw.Draw(image)\n","\n","root.mainloop()\n","\n","'''"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3640945,"sourceId":6326089,"sourceType":"datasetVersion"},{"datasetId":3641022,"sourceId":6326223,"sourceType":"datasetVersion"}],"dockerImageVersionId":30527,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":769.01468,"end_time":"2024-12-22T14:17:15.574113","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-22T14:04:26.559433","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}